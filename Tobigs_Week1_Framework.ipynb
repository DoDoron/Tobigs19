{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1_Library 과제"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Library : 특정한 기능을 구현하기 위해 만들어진 함수들의 집합, 필요할 때 자유롭게 사용할 수 있다.\n",
    "    *   Ex) matplotlib(시각화 라이브러리), BeautifulSoup(HTML파싱 라이브러리)\n",
    "* Framework : 특정 운영 체제를 위한 응용 프로그램를 구현하는 클래스와 라이브러리 모임 여러개의 재사용 가능한 모듈과 패키지를 모아둔 코드 집합체\n",
    "    *   Ex) django, Web2Py\n",
    "* Library는 사용자가 필요할 때 자유롭게 쓰지만, Framework는 정해둔 틀 안에 필요한 코드를 작성하는 것이다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝은 기계학습이라고도 불리우며, 주어진 데이터를 통해 스스로 학습하는 것을 말한다. 빅데이터를 분석하고 가공해서 새로운 정보를 얻고 미래를 예측하는 기술    \n",
    "딥러닝은 머신러닝의 하위 개념으로 인간의 신경망을 따라 만든 인공신경망을 통해 인공지능을 만드는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 아래의 코드에 주석 달기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available\n"
     ]
    }
   ],
   "source": [
    "# pytorch : facebook에서 제공한 딥러닝 도구\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "\n",
    "# torch.cuda설치 여부 확인\n",
    "# 신경망은 CPU보다 GPU사용을 권장하나 아직 cuda설치 전이라 cpu만 사용가능\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(45)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(45)\n",
    "print(device + \" is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9683b660bf1b4dea91a6452388ae40db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f23a0c6f684bc2ab904a19400cf66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18fe08fb67449be87c0d22f23b9e8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14815a5b93494b77a842198f4b24f0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# torch에서 제공하는 데이터셋 중\n",
    "# MNIST 데이터 셋 로드(훈련데이터) \n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        # 데이터의 범위를 0~255에서 0~1사이 값으로 변환\n",
    "        transfroms.ToTensor() \n",
    "    ])\n",
    ")\n",
    "\n",
    "# MNIST 데이터 셋 로드(테스트데이터) \n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataloader를 이용 MNIST 데이터셋 로딩\n",
    "# train, test loader생성\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "# input size를 알기 위해서\n",
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convolutional Neural Networks\n",
    "class ConvNet(nn.Module):\n",
    "  def __init__(self):                                 # layer정의\n",
    "        super(ConvNet, self).__init__() \n",
    "        \n",
    "        # conv : 이미지 특징을 추출하는 층\n",
    "        # input size = 28 x 28\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  \n",
    "        # input channel = 1, filter = 10, kernel size = 5, zero padding = 0, stribe = 1\n",
    "        # ((W-K+2P)/S)+1 공식으로 ((28-5+0)/1)+1=24 -> 24x24로 변환\n",
    "        # maxpooling하면 12x12\n",
    "\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
    "        # input channel = 1, filter = 10, kernel size = 5, zero padding = 0, stribe = 1\n",
    "        # ((12-5+0)/1)+1=8 -> 8x8로 변환\n",
    "        # maxpooling하면 4x4\n",
    "\n",
    "        # 랜덤하게 뉴런을 종료해서 학습을 방해해 학습용 데이터에 치우치는 현상을 막는다.\n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) \n",
    "        # 오버피팅을 방지하고, 연산에 들어가는 자원을 줄이기 위해 출력 값에서 일부만 취해 사이즈가 작은 이미지를 만든다. maxpolling\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        # 4x4x20 vector로 flat한 것을 100개의 출력으로 변경\n",
    "        self.fc1 = nn.Linear(320,100) \n",
    "        # 100개의 출력을 10개의 출력으로 변경\n",
    "        self.fc2 = nn.Linear(100,10) \n",
    "\n",
    "      # 순방향\n",
    "  def forward(self, x):\n",
    "        # 활성화 함수로 쓰이는 ReLU\n",
    "        # convolution layer 1번에 relu를 씌우고 maxpool, 결과값은 12x12x10\n",
    "        x = F.relu(self.mp(self.conv1(x))) \n",
    "        # convolution layer 2번에 relu를 씌우고 maxpool, 결과값은 4x4x20\n",
    "        x = F.relu(self.mp(self.conv2(x))) \n",
    "        x = self.drop2D(x) \n",
    "        x = x.view(x.size(0), -1)          # flat\n",
    "        x = self.fc1(x)                    # fc1 레이어에 삽입\n",
    "        x = self.fc2(x)                    # fc2 레이어에 삽입\n",
    "        # fully-connected layer에 넣고 logsoftmax 적용\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN 객체 생성\n",
    "model = ConvNet().to(device) \n",
    "# 손실함수와 옵티마이저 선택\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbhde\\AppData\\Local\\Temp\\ipykernel_35952\\3803583406.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1]  cost = 0.329685748\n",
      "[Epoch:    2]  cost = 0.111265108\n",
      "[Epoch:    3]  cost = 0.084695518\n",
      "[Epoch:    4]  cost = 0.0729407147\n",
      "[Epoch:    5]  cost = 0.0648430437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(epochs):                     # epochs수 만큼 반복 \n",
    "    avg_cost = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()                   # 모든 model의 gradient 값을 0으로 설정\n",
    "        hypothesis = model(data)                # 모델을 forward pass해 결과값 저장\n",
    "        cost = criterion(hypothesis, target)    # output, target의 손실 계산\n",
    "        cost.backward()                         # backward 함수를 호출해 gradient갱신\n",
    "        optimizer.step()                        # 모델의 학습 파라미터 갱신\n",
    "        avg_cost += cost / len(train_loader)    # loss값을 변수에 누적하고 train_loader의 개수로 나눔 = 평균\n",
    "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test\n",
    "model.eval()            # evaluate mode로 전환 dropout 이나 batch_normalization 해제 \n",
    "with torch.no_grad():   # grad 해제 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        out = model(data)\n",
    "        preds = torch.max(out.data, 1)[1]           # 출력이 분류 각각에 대한 값으로 나타나기 때문에, 가장 높은 값을 갖는 인덱스를 추출\n",
    "        total += len(target)                        # 전체 클래스 개수 \n",
    "        correct += (preds==target).sum().item()     # 예측값과 실제값이 같은지 비교\n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 정규세션 들으시느라 고생 많으셨습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
